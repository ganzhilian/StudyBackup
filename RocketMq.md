---
title: RocketMq
date: 2023-06-11 21:05:02
categories: RocketMQ
tags: RocketMQ
---

# RocketMQ

学习视频：https://www.bilibili.com/video/BV1cf4y157sz/?spm_id_from=333.999.0.0

## 一、概述

### 1、简介

> 就是一个高可用、高并发、高可靠、低延迟的分布式的消息中间件，给消息提供了生产，存储，消费的软件。

### 2、用途

- **流量削锋：**当大量的请求打过来的时候，可以先把这些请求放入到MQ中，避免造成系统的阻塞或者数据库的崩溃。

- **异步解耦：**上游戏对下游系统的同步调用，导致系统的效率低下并且吞吐量低，耦合度还高。一般这种的话可以通过异步调用解决，两层之间换成异步调用，一般的做法是，中间加一个MQ。

  学习博客：https://segmentfault.com/a/1190000038844218

  **比如：**一个业务的需求是：当用户注册成功时，发送短信或者邮箱提示。

  - 同步方案：用户信息落入到注册系统时，在同步调用发短信功能，在调用邮箱功能，然后邮箱发送成功了，在返回告诉短信功能，短信成功了，在返回告诉注册系统，在返回给用户注册成功。对用户体验很糟糕。

- 并行方案：将短信发送和邮箱发送交给不同的线程去处理，等到这两个业务都处理完了，在返回告诉注册系统，注册系统在返回给用户。

  - **异步调用：**用户将信息落入到注册系统时，直接返回告诉用户注册成功，然后注册系统再把信息放入到MQ，MQ再把信息分发到不同的消费者，也就是邮箱和短信的发送功能。

- **数据收集：**对这些海量的数据进行实时或者批量汇总，进行大数据分析。

## 二、基本概念

### 1、消息

message：就是一条数据，有生产者生产，消费者消费。

### 2、主题

**Topic：**就是一堆消息的集合，每个消息只属于一个Topic。

### 3、标签

**Tag：**相当于对消息的一个二级分类，比如一个消息有Topic动物或者Topic植物，则动物的Tag可以是人、狗、猫等。植物的Tag可以是玫瑰、向日葵等。*代表接受某Topic的全部消息。

### 4、队列

**Queue：**用于存放消息的实体。一个Queue只能允许一个消费组中的一个消费者消费，但能不同消费组的一个消费者消费同一个Queue。

### 5、消息标识

**messageId：**分两种信息。

- msgId：由生产者生产，具有一定的唯一性，小概率会重复。

  producerIp + 进程pid + MessageClientIDSetter类的ClassLoader的hashCode +
  当前时间 + AutomicInteger自增计数器

- offsetId：由消费者提供，用于查看消费者消费到了哪条数据。

  brokerIp + 物理分区的offset（Queue中的
  偏移量

**keyId：**用户指定的唯一标识，当用户需要查询某条消息时，可以通过keyId查询。

## 三、系统架构

![](https://s3.bmp.ovh/imgs/2023/06/05/04125b880f21a2c2.png)

### 1、生产者

用户消息的生产。生产生产的消息通过MQ的负载均衡选择相应的Broker集群队列进行投递。一般生产者是以生产者组的形式生产消息，生产者组发送同一Topic类型的消息。一个生产者组可以发送多个Topic的消息。

### 2、消费者

消息的消费。一个消息从Broker队列里面获得消息，并对消息执行相应的业务。消费者一般都是再消费者组里出现，实现了负载均衡（将一个Topic的不同Queue交给消费者组里的不同消费者进行消费）和容错（一个消费者挂了，消费者组里的其他消费者可以接着他的信息消费）

![](https://s3.bmp.ovh/imgs/2023/06/05/ae30bb9fec6b0b37.png) 

**注意：**

- **消费者组的消费者比Topic的队列多时，会造成资源浪费**，多出来的消费者不会消费，因为一个消费者只能对应一个队列，所以尽量保持队列和消费者1：1的关系
- **一个消费者组只能消费一个Topic**
- **不同的消费者组可以消费同一Topic的队列**

### 3、NameServer

#### 功能介绍

就是一个注册中心，主要有**两个功能**：

- **Broker管理：**每个NameServer中维护者Broker列表，记录他们的信息，BrokerId，提供心跳机制，检查是否存活。
- **路由信息管理：**客户端（生产者和消费者）不可能直接通过Broker的连接，毕竟存在着几十个客户端，所以维护着NameServer，让它将客户端与Broker进行连接，从而进行消息的生产和消费。

#### 路由注册

NameServer通常以集群的方式进行部署，并且都是无状态的，相互之间不进行通信。优点：部署简单，缺点：因为Broker必须指出所有NameServer的地址，所以当有新的NameServer启动时，需要Broker去指定（指定的话需要暂停MQ的生产和消费功能，修改配置文件），如果不去指定，就会导致Broker无法注册到NameServer。

**当Broker启动的时候，就会去轮询NameServer列表，发起注册请求，建立长连接。而NameServer维护者一个注册表，记录着所有注册过而且还存活着的Broker。**

Broker为了证明自己还活着，就会向NameServer每隔30秒发送一个**心跳包**，告诉NameServer自己还活着，NameServer就会对该Broker注册表里时间戳进行更新。记录其Broker的Id、名称、所属集群。

#### 路由剔除

每隔10秒NameServer就会扫描注册表，发现有Broker没有发送心跳，就会将该Broker剔除。

#### 路由发现

因为MQ采用Pull模型，所以当NameServer有路由信息发生变动的时候，不会主动去告诉客户端（生产者和消费者），所以需要客户端发起请求的时候才会拉取路由信息，而且每隔一段时间。默认30秒

> - **pull模型：**每隔一段时间进行一次拉取。优点：能处理大的请求，缺点：实时性很差。
> - **push模型：**推送模型，维护一个长连接，每当有数据，就传输数据过去。优点：实时性较高，缺点：处理不到大的请求。
> - **Long Polling模型：**长轮询模型，对Push和Pull的整合，先发起长连接看是否有数据，没有数据，则等待一段时间，还是没有，在返回通知。充分利用这两个的优点，避免了优点。

#### NameServer选择策略

 首先客户端需要配置上NameServer的地址，然后客户端会产生一个随机数对NameServer的数量取模，得到连接索引，进行连接，如果连接失败就会采用round-robin策略，逐个尝试其他的节点。

### 4、Broker

主要用来接受生产者生产的消息，并且将这些信息进行一个存储，消费者则可以通过它进行消息的拉取。同时还存储着一些元数据，比如：消费进度的offset、主题、队列等。

构成：主要有一个Remoting Module（远程处理模块）构成，负责客户端的请求。他由下面四个大模块构成。

1. **Client Manager：**负责接受、解析客户端的请求（生产者/消费者），管理客户端。
2. **Store Service：**存储服务，调用一些API，然后进行消息的存储。
3. **HA Service：**高可用服务，记录Master和slave的关系。
4. **Index Service：**索引服务，可以让客户端根据key进行消息查询，其中有索引帮其加快查询速度。

![](https://s3.bmp.ovh/imgs/2023/06/05/23d54e431cb89bdb.png)

### 5、执行流程

1. **启动NameServer，等待Broker、Producer、Comsumer的连接**
2. **启动Broker，Broker会轮询跟每个NameServer发起注册请求，进行长连接，NameServer会维护一个路由表，用户记录Broker的状态，并且Broker每隔30秒向NameServer发送一次心跳包**
3. **发送消息之前，可以创建Topic，Topic可以指定Broker，会将Topic与Broker的关系记录到NameServer中。也可以不创建，等发消息的时候创建。**
4. **Producer发送消息，会采用算法选择一个NameServer进行长连接，并从NameServer中获
   取路由信息，即当前发送的Topic消息的Queue与Broker的地址（IP+Port）的映射关系，并且会在Producer本地备份一个路由信息，每30秒进行更新一次，然后与Broker进行长连接，再根据策略算法选择一个Queue，将信息发送至Queue中。**
5. **Comsumer与Producer类似，先选择一个NameServer进行长连接，获得与 Broker的路由信息，即Topic消息的Queue与Broker地址的映射关系，然后会在本地备份一次路由信息，30秒更新一次，然后与Broker进行长连接，最后消费其消息。**

##### Topic的创建模式

手动创建Topic时，有两种模式：
集群模式：该模式下创建的Topic在该集群中，所有Broker中的Queue数量是相同的。
Broker模式：该模式下创建的Topic在该集群中，每个Broker中的Queue数量可以不同。
自动创建Topic时，默认采用的是Broker模式，会为每个Broker默认创建4个Queue

## 二、集群搭建理论

### 1、数据复制与刷盘策略

![](https://s3.bmp.ovh/imgs/2023/06/05/55dfe09489145504.png)

在进行集群搭建时，需要知道MQ集群的同步和持久化策略。

#### 复制策略

- **同步复制：**将master数据同步到slave并且同步完的时候，才返回ack给Master。效率低，数据完整性高。
- **异步复制：**master接受到producer的数据后，立马给master返回ack。效率高，吞吐量高。数据完整性低。

#### 刷盘策略

- **同步刷盘：**当消息写入到broker的磁盘的时候才代表写入成功。

- **异步刷盘：**当消息写入到broker的内存的时候就直接返回写入成功，无需等待写入磁盘的过程。

  > 有点像redis的AOF，会写入到缓冲区pageCache，等到一定的信息的时候，才把这一部分的数据写入到磁盘。避免频繁的IO。

### 2、Broker集群模式

#### 单Master

单点故障。

#### 多Master多Slave - 异步复制

可以有多个Master，每个Master可以有多个Slave，Master负责数据的读写，Slave只负责数据的存储和时刻等待与替代Master，但slave替换Master有一段时间间隔，也有少部分数据丢失。因为采用异步复制，所以当producer将数据交给Master的时候就立即返回ACK， 不保证Slave是否备份完整。

#### 多Master多Slave - 同步复制

所谓同步双写，指的是消息写入master成功后，master会等待slave同步数据成功后才向producer返回成功ACK，即master与slave都要写入成功后才会返回成功ACK，也即双写。效率比异步低10%

#### 最佳实践

多Master+RAID阵列

## 三、工作原理

### 1、消息生产

1. **producer会向NameServer发送一个消息Topic的路由信息请求。**
2. **NameServer接受到这个请求的时候，会向producer发送路由表和broker表。**
3. **producer接受这两个表信息时，会在本地存储一份，并且根据选择队列的算法，选择一个队列，为后续存储消息做准备。**
4. **producer会对这些消息进行一个特殊处理，比如消息超过4M，进行压缩.**
5. **producer会向broker进行RPC请求，然后开始发送数据。**

#### 数据投递Queue算法

也称消息投递算法，**两种：**

- **轮询算法：**均衡的向每个Queue分发消息。

  **缺点：**当有大消息过来时，会造成一个消息的阻塞，生产的很慢。

- **最小延迟投递算法：**每次发消息都会统计其延时时间，然后找到最小的那条Queue，让他发送，如果都相同，采用轮询算法。

  **缺点：**如果一直采用最小的那条Queue，导致消息分配不均，吞吐量较小了，导致消息进一步挤压。对消费者也会增大压力。

### 2、消息存储

MQ消息存储一般存储再主用户目录下的store目录下。

![](https://s3.bmp.ovh/imgs/2023/06/06/cde7ad0609a56019.png)

abort：当启动Broker的时候，就会启动，关闭Broker，abort也会消失。如果存在abort，不存在Broker，说明Broker是非正常关闭的。

checkpoint：记录commitlog、consumequeue、index最后一次刷盘的时间戳。

**commitlog：**提交日志，记录着每一条Topic的消息。

**config：**对Broker的一些配置。

**consumequeue：**存放着队列。

index：消息索引文件

lock：运行期间的全局资源锁。

#### commitlog

> 虽然叫commitlog，但在源码中叫的是mappedFile

##### 目录与文件

**commitlog存放着很多mappedFile文件，消息就存放在mappedFile中，一个mappedFile大概存储1G文件，如果满了会开辟新的mappedFile，文件名就由20位二进制树构成。**表示第一个消息的偏移量，所以第一个文件都是20个0开头，第二个文件，如果第一个文件满了1G，那就会在第二个文件将1G换算成20位二进制作为文件名。

值得注意的是，**一个Broker对应一个commitlog目录**，所有的mappedFile都存放在这个目录中。所以无论Broker有多少个Topic信息都会存放在这些mappedFile中。并会按照Topic进行分类。

##### 消息单元

![](https://s3.bmp.ovh/imgs/2023/06/06/47258ecf201d01b2.png)

消息单元存储在mappedFile中，存储着消息总长度、物理地址、消息Body、消息主题Topic、QueueId、生产者、消息发送时间戳等。

### 3、consumequeue

![](https://s3.bmp.ovh/imgs/2023/06/06/a805af796aa41996.png)

#### 目录与文件

为了提高效率，consumequeue目录下，**还创建了Topic目录，然后Topic目录下才存放着相应的queue目录，以queueID存放。consumequeue就是commitlog的索引文件，可以根据consumequeue具体定位到信息。**consumequeue文件名也是20位二进制构成，记录当前文件的偏移量，跟mappedFile不同的是，consumequeue的文件大小固定不变。**consumequeue 文件可以看成是基于 topic 的 commitlog 索引文件**

![](https://s3.bmp.ovh/imgs/2023/06/06/6d1afb474ce762bd.png)

#### 索引条目

![](https://s3.bmp.ovh/imgs/2023/06/06/71f145502b661d57.png)

每个consumequeue文件包含了30w个索引条目，这些索引条目主要记载了消息在mappedFile的commitlog offset的偏移量、消息长度、消息Tag的HashCode，

> 一个consumequeue文件中所有消息的Topic一定是相同的，但每条Tag消息可能是不同的

### 4、broker的持久化

![](https://s3.bmp.ovh/imgs/2023/06/06/c514ebfb0a7ea17a.png)

#### 消息写入

一条消息进入到Broker后经历了以下几个过程才最终被持久化：

1. broker根据queueId，获取该消息对应索引条目在consumequeue目录中写入偏移量，即queueoffset。
2. 对消息进行进一步的封装成消息单元，比如queueId、body等，
3. 将消息写入到commitlog
4. 同时消息形成索引条目
5. 将消息索引条目分到相应的comesumequeue

#### 消息拉取

消费者拉取消息时：

1. 当consumer拉取消息时，需要计算出该消息在队列中的偏移量，也就是i消费到哪了
2. consumer就向broker发送拉取请求，拉取数据，。
3. broker就计算出conesumerqueue的偏移量
4. 然后就从偏移量开始往后查找第一条指定Tag的索引条目
5. 然后开始解析索引条目的前八位，然后定位到消息commitlog中的commitoffst
6. 从对应的comiitlog读取消息单元，并发送个Consumer。

#### 性能提升

MQ消息都是存储在磁盘上，影响消费嘛？

不影响，有mmap零拷贝。还有PageCache机制

### 5、indexFile

没学，感觉不重要。

### 6、消息的消费

消费者有两种消费方式：pull模式和push模式。两种消费模式：集群消费Clustering和广播消费Broadcasting。

#### 消费方式

##### 拉取模式

Consumer主动从Broker中拉取消息，主动权由Consumer控制。一旦获取了批量消息，就会启动消费过
程。不过，该方式的实时性较弱，即Broker中有了新的消息时消费者并不能及时发现并消费。

> 由于拉取时间间隔是由用户指定的，所以在设置该间隔时需要注意平稳：间隔太短，空请求比例会增加；间隔太长，消息的实时性太差

##### 推送模式

**该模式下Broker收到数据后会主动推送给Consumer。该获取方式一般实时性较高。**
该获取方式是典型的发布-订阅模式，即Consumer向其关联的Queue注册了监听器，一旦发现有新的消息到来就会触发回调的执行，回调方法是Consumer去Queue中拉取消息。而这些都是基于Consumer与Broker间的长连接的。长连接的维护是需要消耗系统资源的。

#### 消费模式

##### 广播消费

**广播模式下，每条消息都发送给消费组里的每个消费者。**

![](https://s3.bmp.ovh/imgs/2023/06/06/c61a11ecb615335f.png)

##### 集群消费

**集群模式下，消息会平均分摊给每个消费组里面的消费组。**

![](https://s3.bmp.ovh/imgs/2023/06/06/a153003c96327f88.png)

#### 消费进度保存

- 广播模式：消费进度只会保存在每个消费者组里的消费者，因为在这种模式下，每个消费者消费的进度不同，所以消费者之间保存各自的进度。
- 集群模式：消费进度保存在Broker里面。因为消费组里面的消费者消费的是同一个Topic下的消息，也就是共享同一个消费进度。下图是broker中存放的各个Topic的各个Queue的消费进度。

![](https://s3.bmp.ovh/imgs/2023/06/06/19cad866696aec8c.png)

### 7、Rebalance机制

Rebalance机制讨论的前提是：集群消费。

#### 什么是Rebalance

**就是Consumer的数量变化会促发重新分配。这样做的好处是提高并行消费能力。**

![](https://s3.bmp.ovh/imgs/2023/06/06/3375399fd2c2fefd.png)

#### 限制

一个队列最多分配一个消费者。所以当消费者数量大于队列数量，剩下多余的消费者不会进行消费，分配不到队列。

#### 危害

提升消费能力的同时，也会造成一些危害：

1. **消费暂停：**当触发rebalance时，原来正在消费的一部分队列会先暂停，等待新的消费者进入或者旧的消费者剔除。
2. **消费重复：**consumer在消费分配给自己的队列时，必须接着上一次消费者的偏移量消费。当有consumer在正常消费数据时，突然宕机，其他一个消费者就会继续从宕机的偏移量重新消费。造成消息重复消费。
3. **消费突刺：**因为rebalance会促发队列的部分暂停，所以会导致消息的挤压，如果暂停时间过长，进一步导致部分队列当rebalance结束时突然猛地消费。

#### 产生的原因

两种：queue发生变化，消费者发生变化

> 1）	queue发生数量变化的场景：
>
> - Broker扩容
> - Broker升级
> - Broker与NameServer网络抖动
>
> 2）消费者发生数量变化的场景：
>
> - 消费者的扩容或缩容
> - 消费者运维升级
> - 消费者与NameServer网络抖动

#### Rebalance过程

Broker里面维护着一个Map，key为Topic下的queue信息，value为消费组里面的消费者信息。一旦queue的数量或者消费者的数量发生变化，就会通知消费者组里面的每个消费者进行Rebalance操作。Consumer接受到通知到后会采用**Queue分配算法**，找到自己的queue，然后由Consumer自主进行Rebalance。

### 8、Queue分配算法

queue要分赔给哪个消费者也是需要算法决定的，有三个主要策略：

#### 平均分配策略

就是 **queue的数量 % consumer的数量**，如果能整除，正常分配。不能整除，将剩余下来的消费者从头开始分配。

![](https://s3.bmp.ovh/imgs/2023/06/06/05492f1e2ca90c35.png)

#### 环形策略

像发糖果一样，发给每一个小朋友，queue组成一个环，消费者在消费。

> 该算法不用事先计算每个Consumer需要分配几个Queue，直接一个一个分即可。

![1686060395417](C:\Users\qinfeng\AppData\Roaming\Typora\typora-user-images\1686060395417.png)

#### 一致性哈希

该算法会将consumer的hash值作为Node节点存放到hash环上，然后将queue的hash值也放到hash环上，通过顺时针方向，距离queue最近的那个consumer就是该queue要分配的consumer。

> 该算法存在的问题：分配不均。

![](https://s3.bmp.ovh/imgs/2023/06/06/71f7ee9a03d3898d.png)

#### 总结

顶上两种适合简单且分配效率高的。

一致性哈希算法适合consumer经常变换的，因为Rebalance影响较少。

#### 至少一次原则

RocketMQ有一个原则：每条消息必须要被成功消费一次。
那么什么是成功消费呢？Consumer在消费完消息后会向其消费进度记录器提交其消费消息的offset，offset被成功记录到记录器中，那么这条消费就被成功消费了。

> 什么是消费进度记录器？
> 对于广播消费模式来说，Consumer本身就是消费进度记录器。
> 对于集群消费模式来说，Broker是消费进度记录器。

### 9、订阅关系的一致性

#### 正确订阅关系

一个消费者组只能订阅一个Topic，一个消费者组可以订阅多个queue，一个queue可以被多个不同消费组的消费者消费。

![](https://s3.bmp.ovh/imgs/2023/06/06/aeeb93daef751d9d.png)

#### 不正确的订阅关系

一个消费者组里面的消费者订阅不同的Topic

![1686061431317](C:\Users\qinfeng\AppData\Roaming\Typora\typora-user-images\1686061431317.png)

### 10、offset管理

**这里指的是队列中不同消费者消费的进度**。根据消费记录器的不同，可以分为两种：

#### 本地管理模式

适用于广播模式，每个消费者保存每个队列中的消费进度，每个消费者不存在消费进度的交集，所以都是采用本地管理。

> Consumer在广播消费模式下offset相关数据以json的形式持久化到Consumer本地磁盘文件中

#### 远程管理模式

适用于集群模式，因为每个消费组里的消费者消费同一Topic下的queue，所以他的消费进度是共享的。

> Consumer在集群消费模式下offset相关数据以json的形式持久化到Broker磁盘文件中，

Broker启动时会加载这个文件，并写入到一个双层Map（ConsumerOffsetManager）。外层map的key为topic@group，value为内层map。内层map的key为queueId，value为offset。当发生Rebalance时，新的Consumer会从该Map中获取到相应的数据来继续消费。
集群模式下offset采用远程管理模式，主要是为了保证Rebalance机制。

#### offset过程

在代码可以指定我们所需要消费的起始位置：

- 从queue第一条消息开始消费
- 从queue最后一条消息消费
- 从时间戳开始消费。

![](https://s3.bmp.ovh/imgs/2023/06/06/7042d62d3e26ffe8.png)

**当消费完一批消息后，消费者会向Broker发送消息消费的偏移量，Broker收到这个偏移量的时候，会记录到ConsumerOffsetManager里面，这是一个Map，还有写入到broker的文件中，然后返回给consumer一个ack确认，这个ack记录着下次消息的偏移量，最小偏移量，最大偏移量。**

#### 重试队列

当消息消费异常时，系统在发生消息消费异常时会为当前的topic@group创建一个重试队列，该队列以%RETRY%开头，到达重试时间后进行消费重试。

![](https://s3.bmp.ovh/imgs/2023/06/06/ee9a15835bc38ffa.png)

#### offset的同步提交与异步提交

集群消费模式下，Consumer消费完消息后会向Broker提交消费进度offset，其提交方式分为两种：
同步提交：消费者在消费完一批消息后会向broker提交这些消息的offset，然后等待broker的成功响
应。若在等待超时之前收到了成功响应，则继续读取下一批消息进行消费（从ACK中获取nextBeginOffset）。若没有收到响应，则会重新提交，直到获取到响应。而在这个等待过程中，消费者是阻塞的。其严重影响了消费者的吞吐量。

异步提交：消费者在消费完一批消息后向broker提交offset，但无需等待Broker的成功响应，可以继续读取并消费下一批消息。这种方式增加了消费者的吞吐量。但需要注意，broker在收到提交的offset后，还是会向消费者进行响应的。可能还没有收到ACK，此时Consumer会从Broker中直接获取nextBeginOffset。

### 11、消息的幂等性

#### 什么是幂等性

就是一次请求和多次相同请求对业务的影响相同，这就叫幂等性。

#### 消费重复的场景分析

什么情况下会消费重复，以下三种情况：

##### 发送时重复

当一条消息发送到Broker并持久化时，这个时候由于网络中断，导致Broker未能对生产者的相应，如果此时生产者意识到消息发送失败并尝试再次发送，这个时候Broker就会出现两条内容相同和messageId也相同的消息。

##### 消费时重复

消息已投递到消费者并执行完业务，此时发送网络中断，消费未能对Broker相应ACK，Broker没有接收到ACK，那么就会从旧的消息偏移量开始，将消息发送出去，此时消费者会接收到同一个MessageId和内容相同的消息。

**解决：消费时，根据唯一标识进行过滤。**

##### Rebalance时重复

当有queue或者消费者的数量发生变动时，会造成Rebalace进而导致消费重复，因为消费者的变化会导致充旧的偏移量重新消费数据。比如5个queue、6个消费者，当第五个消费的消费者挂掉时，无法将消费一半的偏移量返回给Broker，第六个消费者顶上，会接着旧的Broker里的偏移量消费。

------

##### 以下是Java情况

- **哪些情况下客户端是防止不了重复提交的**？

虽然我们可在客户端做一些防止接口重复提交的事（比如将订单按钮置灰，跳转到结果页等）， 但是如下情况依然客户端是很难控制接口重复提交到后台的，这也进一步表明了**接口幂等和防止重复提交不是一回事**以及**后端接口保证接口幂等的必要性**所在。

1. **接口超时重试**：接口可能会因为某些原因而调用失败，出于容错性考虑会加上失败重试的机制。如果接口调用一半，再次调用就会因为脏数据的存在而出现异常。
2. **消息重复消费**：在使用消息中间件来处理消息队列，且手动ack确认消息被正常消费时。如果消费者突然断开连接，那么已经执行了一半的消息会重新放回队列。被其他消费者重新消费时就会导致结果异常，如数据库重复数据，数据库数据冲突，资源重复等。
3. **请求重发**：网络抖动引发的nginx重发请求，造成重复调用；

------

#### 通用解决方案

**实际过程中主要用：分布式锁+唯一标识**

1. 当有网络波动重复的请求过来时，使用分布式锁进行拦截，注意锁的key为业务的唯一标识。
2. 请求进来时，根据唯一标识查询Redis中是否存在，存在则说明该业务已经处理，直接返回，不存在说明第一次进来，进入下一步。
3. 进入数据库查询，如果数据库也没有，说明真的是第一次进来，执行业务，更新MySQL，更新Redis。

------

**还有几种处理方案：Token或者乐观锁**

**1-1-实现思路**
为需要保证幂等性的每一次请求创建一个唯一的标识token,先获取token,并将此token存入到redis,请求接口时，将此token放在header或者作为请求参数请求接口，后端接口判断redis中是否存在此token;

- 如果存在，则正常处理业务逻辑，并从redis中删除此token,那么，如果是重复请求，由于token已经被删除，则不能能够通过校验，返回重复提交
- 如果不存在，说明参数不合法或者是重复请求，返回提示即可

**1-2-请求流程**

- 当页面加载的时候通过接口获取token
- 当访问接口时，会经过**拦截器**，如果发现该接口中有**自定义的幂等性注解**，说明该接口需要验证幂等性（查看请求头里是否有key=token的值，如果有，并且删除成功，那么接口就访问成功，否则为重复提交；
- 如果发现该接口没有自定义的幂等性注解，则放行。

------

### 12、消息堆积与消费延迟

#### 概念

消息堆积：生产者生产的速度大于消费者消费的速度，导致MQ积压的消息越来越多。

消费延迟：如果是一些实时性很强的业务，消息堆积就会进一步导致消息延迟。

#### 产生原因

Consumer将本地缓存的消息提交到线程中，使用业务逻辑对消息进行处理，处理完毕后将处理成功的消息返回给Broker，这才将消息消费完毕。消费者的消费能力取决于消息的**消费耗时**和**消费并发**。如果由于业务复杂等原因，导致处理消息时长较长，此时就会导致Consumer本地缓冲队列达到上限，停止从服务端拉取消息。

##### 结论

 消费堆积的主要原因取决于客户端的消费能力，消费能力取决于消息的**消费耗时和消息并发**。注意消耗耗时的优先级大于消息并发，因为应该在保证消息耗时的基础上，才能进一步优化消息并发。

#### 消费耗时

影响消耗时长的主要就是一个代码逻辑。而影响消耗时长的主要分两种：一 CPU内部计算型代码，二 外部I/O操作性代码。一般来说CPU的处理是非常快速的，所以主要问题在于外部I/O操作型代码。

**I/O操作型代码：**

- 读写外部数据库，比如MySQL的远程
- 读写外部缓存系统，例如对远程Redis的访问
- 下游系统调用，例如Dubbo的RPC远程调用，Spring Cloud的对下游系统的Http接口调用

#### 消费并发度

消费并发度取决于**单节点线程数和节点数量**，一般是通过调整单节点线程数数量进行优化，不行的话，在横向拓展。

> 单节点线程数：一个消费者所包含的线程数
>
> 节点数量：一个消费组下的消费者数量。
>
> 对于普通消息、延时消息和事务消息的并发度计算都是单节点线程数 * 节点数量，但是对于顺序消息，其并发度等于Topic的queue分区数量。
>
> 1）**全局顺序消息：**因为是全局消息，所以该Topic下只允许有一个queue，并且消费者只有一个线程，这样就能保证其消费的有序性。
>
> 2）**分区顺序消息：**分区消息，故名该Topic下的queue是分区的，并且有很多queue，为了保证其一个有序性，这些消费者只能由一个线程消费属于自己的queue。能够保证其Topic下的每个queue中的消息被顺序消费，但不能保证其Topic的整体有序。

#### 如何避免

**消费耗时：**

1. 查看代码的复杂度是否过高，代码是否存在递归，死循环。
2. IO操作能否用缓存规避。
3. 消费逻辑中的复杂耗时操作是否可以交给异步去处理，如果可以，是否会造成逻辑混乱。

##### **消耗并发度：**

1. 提高消费者的线程数，测试观察，找到一个单个节点最优的值。

### 13、消息的清理

消息被消费过后会立马删除嘛？不会。

因为消息是存在commitlog文件里面，是以消息单元的形式存在的，如果要单独删除这一条消息无疑是消耗巨大的。**所以commitlog为单位进行清理。**

commitlog存在一个**过期时间：72小时**，即3天。除了手动清理外，还存在一下几种情况。

- **文件过期，且到达清理时间点（默认为凌晨4点，因为凌晨人少）后，自动清理过期文件**
- **文件过期，且磁盘空间占用率已达过期清理警戒线（默认75%）后，无论是否达到清理时间点，都会自动清理过期文件**
- 磁盘占用率达到清理警戒线（默认85%）后，开始按照设定好的规则清理文件，无论是否过期。默认会从最老的文件开始清理
- 磁盘占用率达到系统危险警戒线（默认90%）后，Broker将拒绝消息写入

## 四、应用

### 1、普通消息

消息的发送分为好3种：

#### 同步发送

producer发送一条消息后，等待Broker返回ack确认后，producer才能继续往下发送。效率较低，但保证了消息的可靠性。

![](https://s3.bmp.ovh/imgs/2023/06/07/3ce9be1d84d9bed5.png)

#### 异步发送

发送消息后，不等待broker的确认，接着发送剩下的信息。但能异步收到这些消息的确认信息。效率最高，消息也有一定的可靠性。**异步消费，如果要关闭的话，需要提前假设好睡眠时间，因为异步发送，可能还在发送，就直接关闭，造成报错。**

![](https://s3.bmp.ovh/imgs/2023/06/07/d52dcd8eb0d7508d.png)

#### 单向发送消息

直接发送消息，不等待ACK，也不处理ACK。效率很高，但消息可靠性不保证

![](https://s3.bmp.ovh/imgs/2023/06/07/43ab188162dca299.png)

### 2、顺序消息

**顺序消息指的是生产者生产的消息，消费者顺序消息（FIFO）**

消息的发送默认按照轮询方式发送给Topic下不同分区的queue，然后消费者以拉取的方式从queue中拉取数据进行消费，很难保证一个发送和消费是有序的。但如果发送的时候只有一个queue，消费的时候也只有一个队列并且消费者只有一个线程，这个时候能保证消息的顺序性。

#### 为什么需要顺序消息

因为有些业务中需要一个消息的有序消费，比如一个订单的未支付，已支付，发货中，发货失败，这是个有序任务，当发到不同的queue中时，会造成业务逻辑处理的混乱。

![](https://s3.bmp.ovh/imgs/2023/06/07/7f54285221574466.png)

所以为了进一步保证有序性，发送消息时就使用一个queue，消费时也就采用要1个队列，并且消费者只有一个线程

![](https://s3.bmp.ovh/imgs/2023/06/07/055b46a75bdf0b31.png)

#### 有序性分类

#### 全局有序

发送消息时只有一个队列，消费时只有一个队列而且只有一个消费线程

> 在创建Topic时指定Queue的数量。有三种指定方式：
> 1）在代码中创建Producer时，可以指定其自动创建的Topic的Queue数量
> 2）在RocketMQ可视化控制台中手动创建Topic时指定Queue数量
> 3）使用mqadmin命令手动创建Topic时指定Queue数量

![](https://s3.bmp.ovh/imgs/2023/06/07/3f3b9e6cec92a1f7.png)

#### 分区有序

分区有序指的是同一Topic下，不同分区的queue消费消息的顺序能够保证，当消费者只有一个线程时，不能保证一个Topic下的全局有序。

### 3、延时消息

消息进入到broker之后，过段时间才会被消费。

![](https://s3.bmp.ovh/imgs/2023/06/07/6862ec93848561b9.png)

#### 延时等级

延时等级对应着其延时时长。

![](https://s3.bmp.ovh/imgs/2023/06/07/4b548f4ccfb17538.png)

#### 实现原理

![](https://s3.bmp.ovh/imgs/2023/06/07/08b491d3e613fb3e.png)

1. 当生产者生产一条消息并写入到commitlog，然后准备将该信息分发到相应的consumerqueue队列之前，会判断这个信息是否设置延时等级，如果没有，正常消息。

2. 如果设置了，该消息就会根据延时等级就会进入一个特殊队列SCHEDULE_TOPIC_XXX。

3. 并且会修改原有消息的索引条目，原来的Tag的哈希值修改为投递时间，投递时间指的是进入Broker写入commitlog的时间，然后将该信息放入到特殊队列里。

   ![](https://s3.bmp.ovh/imgs/2023/06/07/fd9c79b87be88f23.png)

4. 然后会有一个周期类，这个类会随着broker的启动创建一个定时器，定时的去执行任务，每个等级不同，就会有不同的定时任务，这个类回去查看等级的第一条信息，发现第一条都没有到期，后面队列的肯定没有到期。

5. 有消息到期了，这个类会重新把这个消息从特殊队列拿出来，将原来commitlog的消息的延时等级设置为0，然后投递相应的Topic。

   

### 4、事务消息

**RokcetMQ的的分布式事务，只能保证一个生产者到Broker的事务消息，无法保证到消费者的一个事务**

**分布式事务和普通事务一样，没什么区别，都是保证数据的一致性。最大的区别是保证的范围不一样，分布式是将一个操作划分为若干分支，这些分支部署在不同服务器上，分布式事务就是为了保证这些分支要么全部成功，要么全部失败。**

有点难、、、、

### 5、批量消息

默认情况下消费者只能消费一个消息，但是可以修改消费者的消费数量来达到批量消费的功能，最多只能拉取32条信息。但是生产者需要注意批量消息不能超过4M，超过4M需要进行消息分割。

**发送限制**
生产者进行消息发送时可以一次发送多条消息，这可以大大提升Producer的发送效率。不过需要注意以下几点：

> 批量发送的消息必须具有相同的Topic
>
> 批量发送的消息必须具有相同的刷盘策略
>
> 批量发送的消息不能是延时消息与事务消息
>
> 批量消息不能超过4M

#### 存在问题

消费者批量消费是不是批量越多越好？不是

- 若拉取过大，导致每次需要的时间很长，出现错误的可能性就很高，一旦发生错误，那么所有信息要重新拉取。
- 设置的越大，消费者的并发能力就越低，且这批消息具有相同的结果，因为批量消费指定只有一个线程进行消费，处理过程中出现异常，就要重新消费。

### 6、消息过滤

除了Topic过滤之外，还存在两种想对比Topic粒度更细的消息过滤。

- Tag过滤
- SQL过滤

#### Tag过滤

如果消费者要订阅多个Tag，中间用”||“隔开

```java
DefaultMQPushConsumer consumer = new
DefaultMQPushConsumer("CID_EXAMPLE");
consumer.subscribe("TOPIC", "TAGA || TAGB || TAGC");
```

#### SQL过滤

SQL过滤可以实现复杂的消息过滤，不过只能在PUSH模式下使用。

SQL过滤表达式中支持多种常量类型与运算符。
支持的常量类型：

- 数值：比如：123，3.1415
- 字符：必须用单引号包裹起来，比如：'abc'
- 布尔：TRUE 或 FALSE
- NULL：特殊的常量，表示空

支持的运算符有：

- 数值比较：>，>=，<，<=，BETWEEN，=
- 字符比较：=，<>，IN
- 逻辑运算 ：AND，OR，NOT
- NULL判断：IS NULL 或者 IS NOT NULL

### 7、消息重试

#### 顺序消息

对于顺序消息，如果消费不成功，就会不断去重试，并且为了保证其有序性，其他消息会进行一个阻塞。直至消费成功。

#### 无序消息

无序消息指的是普通消息、延迟消息和事务消息，如果这些发送失败，会间隔一段时间重新发送，而且重试时间会逐渐变长，如果发送16次还是失败，会把该消息扔到死信队列。

重试次数 与上次重试的间隔时间 重试次数 与上次重试的间隔时间
1 10秒 9 7分钟
2 30秒 10 8分钟
3 1分钟 11 9分钟
4 2分钟 12 10分钟
5 3分钟 13 20分钟
6 4分钟 14 30分钟
7 5分钟 15 1小时
8 6分钟 16 2小时

#### 重试队列

对于重试消息，会为其创建一个该Topic下的一个特殊队列，重试队列，当有消息需要重试时，会把这个消息设置延时等级，把他扔到延时队列里面，如果时间到了，就会重新放到重试队列里面，进行重新消费。

#### 重试配置方式

一般都是在catch中直接返回。

集群消费方式下，消息消费失败后若希望消费重试，则需要在消息监听器接口的实现中明确进行如下三
种方式之一的配置：
方式1：返回ConsumeConcurrentlyStatus.RECONSUME_LATER（推荐）
方式2：返回Null
方式3：抛出异常

![](https://s3.bmp.ovh/imgs/2023/06/08/829fcf00314198ac.png)

#### 不重试配置方式、

集群消费方式下，消息消费失败后若不希望消费重试，则在捕获到异常后同样也返回与消费成功后的相同的结果，即ConsumeConcurrentlyStatus.CONSUME_SUCCESS，则不进行消费重试。

![](https://s3.bmp.ovh/imgs/2023/06/08/1bedf48c90c84190.png)

### 8、死信队列

当一条消息不断发送失败，达到一个最大的发送失败次数，不会把这个消息丢弃，会把这个消息放到一个特殊的队列，也就是死信队列。死信队列就是用来处理未能正常处理的消息。

#### 特征

死信队列具有如下特征：

- 死信队列中的消息不会再被消费者正常消费，即DLQ对于消费者是不可见的
- 死信存储有效期与正常消息相同，均为 3 天（commitlog文件的过期时间），3 天后会被自动删除
- 死信队列就是一个特殊的Topic，名称为%DLQ%consumerGroup@consumerGroup，即每个消费者组都有一个死信队列
- 如果⼀个消费者组未产生死信消息，则不会为其创建相应的死信队列

#### 处理

实际上，当⼀条消息进入死信队列，就意味着系统中某些地方出现了问题，从而导致消费者无法正常消
费该消息，比如代码中原本就存在Bug。因此，对于死信消息，通常需要开发人员进行特殊处理。最关
键的步骤是要排查可疑因素，解决代码中可能存在的Bug，然后再将原来的死信消息再次进行投递消
费