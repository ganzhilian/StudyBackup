---
title: Redis
date: 2023-06-11 21:04:05
categories: Redis
tags: Redis
---

# Redis

## 1、分布式锁

### 1.1 刚需

- 独占性：只能让一个线程获得。
- 高可用：不能让一个节点挂了之后，就无法获得锁或者释放锁，高并发下性能OK。
- 防死锁：杜绝死锁，必须有个超时方案或者撤销操作，有个兜底操作跳出死锁。
- 不乱抢：就是不要张冠李戴，不要乱释放别人的锁。自己的锁含着泪也要自己释放。
- 可重入：同一个节点的同一个线程获得锁之后，还可以获得锁。

### 1.2 演变

1. 最垃圾的**synchronized、Lock锁**。原因，因为这两个锁锁住得都是不同节点的锁，所以压根不能锁住同一资源，也就是**缺少独占性**。

2. 用if判断是否获取到锁，当获取不到锁时，进行停止两秒，避免频繁消耗CPU，之后递归让其重试。

   **改进：递归调用可能会陷入一个StackOverflow**，不太完善进一步改为以CAS的方式获取锁，失败了就停两秒让**while**不断重试。

   ![](https://s3.bmp.ovh/imgs/2023/06/01/f1ed2f4383e559df.png)

3. **部署Java的微服务宕机了，释放锁没有走到finally这一块，无法释放锁，进入死锁状态。**

   **改进：**锁设置过期时间。

4. **锁的过期时间太短可能会导致误删别人的锁。**当线程A在执行任务时，此时锁过期了，线程B抢到锁，B还在执行任务，A执行任务结束，finnaly释放锁，这个时候就会删掉B的锁。

   **改进：**释放锁时加一个判断是否为同一个value

   ![](https://s3.bmp.ovh/imgs/2023/06/01/c0b2a32d03bcc548.png)

5. **判断是否为同一个锁然后再删除不是一个原子操作。**

   **改进：**使用Lua脚本，将判断和删除写在一个脚本里。

   ![](https://s3.bmp.ovh/imgs/2023/06/01/fdd9c9d46dff8d8f.png)

6. **可重入锁**没学，

7. **自动续期：**防止业务还没结束锁就过期了。另起一个异步线程，每过一段时间去监视锁是否过期，写一个Lua脚本判断是否锁还有，还有重新续上，没有直接结束。

### 1.3 Redisson

#### 1.3.1 RedLock算法

为了解决Redis分布式锁单点故障，导致无法获得锁或者释放锁的问题，还有一个影响就是，如果采用主从复制的分布式锁，当A线程获得master的锁，但是没有同步到slave，master就挂掉了，然后slave通过哨兵升级为master，此时B获得新的一把锁，造成一锁多键，问题很严重。为了解决这个问题：引入了红锁算法，就是多个master机器，不存在slave，当一个线程获得机器半数以上的锁时，才能正确加锁成功，否则其余不合格的锁会自动过期。一般是五个机器。

## 2、数据类型

### 2.1 String

**功能：**

> - 一次性设置多个键值对，或者设置多个key
> - 截取value的值
> - 数值增减
> - 获取字符串长度和内容增加
> - 分布式锁
> - 先get再set

**需求：**

> - 抖音点赞数
> - 是否喜欢的文章

### 2.2 List

**功能：**

> - 左插右插，左出右出，双向链表
> - 获取指定下标的元素和获取长度
> - 截取开始到结束的元素并赋予新的key（用于分页）
> - 删除N个value值
> - 已有值插入新的值

**需求：**

> - 微信公众号的订阅（用分页）

### 2.3 Set

**功能：**

> - 一次性添加多个value
> - 判断元素是否在其中、删除元素、value长度
> - 随机获取一个元素，可删除或者不删除
> - 并集、交集、差集

**需求：**

> - 微信小程序抽奖
> - 微信点赞查看同赞朋友
> - qq内推可能认识的人

### 2.4 ZSet

**功能：**

> - 获取指定分数范围内的元素
> - 获取按分数从小到大的元素
> - 增加某个元素的分数
> - 删除某元素、获取key的个数

**需求：**

**在面对需要展示最新列表、排行榜等场景时，如果数据更新频繁或者需要分页显示，建议使用ZSet**

> - 按商品销售的数量进行排序显示

### 2.5 bitmap

需要对用户ID得到哈希值，根据哈希值除以2^32次方，得到偏移量，然后setbit 日期 偏移量（用户ID） 1，因为正常业务不可能是直接用户ID，肯定要计算出偏移量。

**功能：**

> - 设置某一位下标为0或者1
> - 统计字节数（超8位长度+1），统计有几位1
> - 交集、并集

**需求：**

> - 统计用户一年的登录次数，哪天登陆过，哪几天没登陆过
> - 上下班签到统计
> - 黑名单
> - 日活统计
> - 最近一周活跃的用户

### 2.6 HyperLogLog

**统计巨大的数据**

**功能：**

> - 添加元素到HyperLogLog，PFADD key value【value。。。】
> - 返回估算值

**需求：**

> - 用户搜索关键词 的数量
> - 统计网站的特殊客户的访问量

### 2.7 GEO

**功能：**

> - 添加经纬度
> - 获取周围半径的城市
> - 获取位置和两点距离

**需求：**

> - 美团附近酒店推送
> - 高德附近核算检查点

### 2.8 Stream

想增加MQ的功能给redis，但是比较垃圾，没有持久化，是由一种队列构成

## 3、 持久化

### 3.1 RDB

**在指定时间间隔内将内存中的数据快照写入磁盘，恢复时再从快照文件中读取到内存。**

你可以修改配置文件，比如每5秒进行2次数据操作时进行数据备份，然后自动记录到RDB文件中，还有一种手动的方式，调用save/bgsave命令，

- save会阻塞当前主线程，直到持久化结束，执行save命令期间，redis线程不能进行其他操作，一般不用
- bgsave在后台异步操作，不会阻塞，会fork一个跟父线程相同的子线程，由子线程进行持久化操作

**优点：速度相对来说比AOF快，并且适合大规模的数据持久化，并且这些数据不是特别的重要，对数据的一致性不高。**

**缺点：当redis出现单点故障时，无法持久化最后一次的操作数据，就是可能会损失一部分的数据，因为是在一定时间间隔内做的备份，所以只能保存最近一次的快照数据**

### 3.2 AOF

**以日志的形式记录每次写操作，读不记录，不断追加文件，但不可以改写文件，redis重启的话，根据日志文件内容将写指令从前到后执行一次完成数据的恢复工作。**

**流程：**

1. **当有命令过来的时候，会先落入到AOF的一个缓存区中，这个缓冲区的作用就是为了减缓IO的次数，当到达一定命令的时候再把这些命令写入到磁盘。**
2. **AOF缓存区会根据采用的写回策略将这些指令写入到磁盘。**
   - **每秒进行持久化操作**
   - **每次操作进行持久化操作**
   - **NO，什么都不做，采用默认的缓冲区达到一定数量的写命令，再放入到磁盘中**
3. **因为是不断写入到AOF文件中的，所以会导致文件不断变大，这个时候会对文件进行一定的压缩处理，也就是AOF重写机制，将命令进行合并**
   - **重写机制：**对AOF文件进行压缩，只保留恢复数据的最小指令集，看不懂流程，放弃。
4. 重启时，运行AOF文件的每一条写命令

## 4、 事务

redis事务跟mysql事务存在很大的区别，不能回滚，没有隔离性，他不是mysql的要么全部执行，要么不执行。redis的事务，只**保证有序性，一次性**，并且他是再**队列**当中执行的。当有个命令出错时，不会影响其他命令的执行。

## 5、 管道

优化频繁命令往返造成的性能瓶颈。一次性执行更多的redis命令，可以通过文件读取

**与传统的mset、mget命令相比，**

- 原生命令是原子性、pipeline缺少原子性
- 原生命令是只能执行一种命令，而管道能读取很多命令，也可以通过文件。

**缺点：**1、缺少原子性，所以一旦有一条发生错误，无法回滚，会继续执行后面的命令，2、不能过多命令，否则可能会造成一些堵塞，因为服务器端会回复一个队列答复。

## 6、发布订阅

**发布的信息不能持久化，信息丢了就没了，很垃圾，不建议采用**

## 7、主从复制

一个主节点可以对应多个从节点。主节点用来写，从节点用来读。

**复制原理和工作流程：**

1. **配置好配置文件时，从节点会向主节点发送一个同步命令**
2. **节点收到这个同步命令的时候，就会在后台起一个线程进行RDB操作，数据备份操作，这个时候主节点肯定还是会接收到客户端传过来的写命令，就会先把这些命令放到缓存中，等到主节点持久化完成之后，从节点就会从缓存和RDB文件中进行数据复制。**
3. **主从都完成数据复制时，就会互相ping通，这个需要自己开启，默认的话每10秒进行ping**
4. **之后的话主节点有新的修改命令自动传给从节点，完成同步**
5. 从机下线。。。

**缺点：一个master挂掉了，会影响到其他从节点，不会自动选举出master，需要手动选配置。**

## 8、哨兵(sential)

**当一台主机器宕机的时候，哨兵就会通过投票机制，将slave选举出新的master。**

**流程：**

1. 正常运行
2. 发现某台master可能要下线，**两种方式判断是否下线**：
   - **SDown主观下线：当一台master被哨兵无法ping通时，一般在30秒，可以在配置文件进行设置，当前这台哨兵就会主观的认为这台master已经出故障了。**
   - **ODown客观下线：客观下线区别在于，当超过半数哨兵认为这台master宕机时，才会认为这台master确实出故障了，需要选举新的master。**
3. **当真出故障时，哨兵之间会选举出兵王，让兵王去选举新的master（Raft算法）**
   1. **选举出新的master，三种选择方式** 
      - **会根据从节点的配置文件的优先级，看哪个slave的优先级比较高**
      - **看从节点的offset，谁复制的数据最新**
      - **最后是RUN ID**
   2. **选举出来的从节点执行slaveof no one成为新的主节点，并通过slaveof命令让其他从节点成为新的master的从节点。**
   3. **老master回来也会让其称为从节点**

**优点：高可用**

**缺点：当master挂掉时，会有一小段时间需要选举，此时不能保证数据的零丢失**

## 9、集群(cluster)

**有多个master，master可以有多个slave。**

能干嘛：1、集群自带哨兵的故障转移，内置了高可用的支持，无需哨兵功能。2、不需要连接集群的所有节点，只需要连接一个可用节点即可。3、槽位slot负责分配各个物理节点。

**过程：当数据过来的时候，会根据CRC算法得到哈希值再模上16384得到哈希槽，再根据哈希槽分配到各个集群，因为哈希槽的范围是根据集群master的数量变化而变化的。**槽位映射有三种，一般采用第三种：

1. 哈希取余分区，有多个集群哈希值对其取余得到槽位，当集群扩容或者递减时，对数据迁移影响比较大。
2. 哈希环算法，目的是为了减少master数量的变化所导致数据映射的变化。哈希环本质就是【0，2^32-1】构成一个环，哈希值对这个环进行取余，就可以得到master部署的位置。当有数据过来时，就会落到哈希环上，然后看距离哪个master最近，然后这个数据就会落到哈希环上的master上，当有新的机器减少时，只会影响附近最近的master节点，扩容同理。**优点：容错性和拓展性很强**，**缺点：当多个master落到一起时，会造成数据倾斜，有些节点的数据很多，有些节点的数据很少**
3. **哈希槽分区，CRC16（key） mod 16384**

**虽然采用哈希槽算法，但是机器扩容或者减少时还是需要对哈希槽进行手动的重新分配**

## 10、单线程？多线程？

**实际上到5、6、7版本之后redis开始启用多线程处理其他事情，4之前一直都是单线程。① 所谓的单线程其实是主线程去处理客户端传来的网络IO和键值对读写请求，但发现多线程能够提高redis的吞吐量，比如异步删除大key，RDB、AOF，以及集群的数据同步。都是多线程的处理，缓解了主线程的压力。Redis命令工作线程是单线程的，但整个Redis是多线程的。② 但6、7版本对多线程发生了比较大的改动，因为Redis跟内存和网络带宽有关，跟CPU无关，因为多线程，无需上下文切换，但是目前内存处理数据速度非常快，所以Redis最大的性能瓶颈只能是网络带宽了，也就网络请求速度跟不上底层网络硬件的速度。为了解决这个问题，所以就引入多线程去处理网络IO请求，提高网络请求处理的并行度。但是多线程只是用来处理网络IO请求的，主线程的读写还是采用单线程，因为避免多线程出现的数据共享问题。**

**Redis单线程快的原因：**

- **基于内存：**数据都在内存，且运算都是内存级别的。
- **数据结构简单：**redis的数据结构都是专门设计的，而这些数据结构查找和操作的时间都是O(1)级别的
- **IO多路服用：**利用IO多路复用监听多个socket请求，用一个线程去处理多个请求，避免了请求带来的阻塞问题。
- **避免上下文切换：**因为Redis工作线程是单线程的，避免了多线程的一个频繁的上下文切换，所以对数据的处理都是有序的，也避免了多线程对数据共享的问题。

**单线程引发的问题（引入多线程的原因）：**

- **bigkey删除：**删除的key是个非常大的对象时，比如包含了成千上万个元素的hash集合，那么del命令会造成主线程的阻塞，无法处理其他命令。**解决：**所以就引入了异步删除的几个命令，开启了一个线程。
- **RDB持久化save命令阻塞**

**网络多线程：**从Redis6开始，就新增了多线程的功能来提高 I/O 的读写性能，他的主要实现思路是将主线程的 IO 读写任务拆分给一组独立的线程去执行，这样就可以使多个 socket 的读写可以并行化了，采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络IO的时间消耗），将最耗时的Socket的读取、请求解析、写入单独外包出去，剩下的命令执行仍然由主线程串行执行并和内存的数据交互。

### 10.1 bigkey

**String超过10kb，List，Set，ZSet等元素超过5000作为大Key。**

**危害：**

- 内存不均，导致集群迁移困难

- 删除时，导致主线程一个阻塞

- 网络流量阻塞

  **产生原因：**社交类：粉丝数目逐级递增。汇总统计：某个报表，每年每月每日统计

如何发现：提供了两个命令，一个找到bigkey，一个计算每个key占用的字节。

**如何删除bigkey**：每个数据结构的删除方法不一样，String一般用del，大的花用unlink，其他特殊的数据结构可能需要逐步删除，不能一下子删除全部。

**如何优化bigkey：**

- 配置文件可以优化
- 拆分处理，按照日期拆分多个。
- 过期时间尽量不要集中在一起。

## 11、RM一致性

**四种方案**

1. **先更新MySql，在更新Redis。问题**：MySQL更新结束，正准备同步到Redis时，发生异常或者网络抖动，Redis的数据没有进行更新，会导致数据不同步，比如MySQL减了1变为99，而线程Redis还是100，可能会超卖，还有一种情况是多线程引发的不同步。
2. **先更新缓存，在更新MySQL。问题：**多线程情况下可能会导致先把Redis的操作执行结束之后，再去更新MySQL，比如先执行A、B两个线程的Redis更新操作，然后再执行MySQL的更新操作，此时可能B是最新的数据，B先更新了，A才更新，使得数据库的数据变为脏数据且和Redis的数据不同步。
3. **先删除缓存，在更新MySQL。问题：**多线程情况下，A线程删除缓存，然后开始更新MySQL，但是执行MySQL的时间还未结束，B线程进来了，发现Redis为空，就去MySQL找，这个时候就会读取到MySQL暂未更新的值，然后B线程就去同步到Redis，这个Redis还是旧的值。造成数据不同步。**解决办法：延时双删。缺点：不好设置延时时间**
   - **延时双删：A线程处理业务的时候先删除Redis，然后去更新MySQL，更新完之后，先延时等待，也就是sleep几秒钟，等待B处理完，然后删除B可能更新的Redis，当其他线程发现Redis为空时，就会从新去MySQL找，避免了读取到Redis旧的MySQL的值**
4. **推荐：先更新MySQL，在删除Redis。问题：**A线程在更新MySQL，没有同步Redis，B线程拿到Redis旧的值，之后A才更新Redis。**解决办法：**MySQL更新完或者删除完的信息先放入到binlog日志中，订阅信息提取出需要的数据和key，再起另一段非业务代码获得该信息，尝试删除缓存操作，发现删除失败，将这些信息重新放入到消息队列，然后重试，重试到一定数量发现还是不能删除缓存时，这个发信息通知运维人员。如果真的要做到一致性，客户端发来的请求就要暂停，等同步完请求才能继续，非常不推荐。

### 11.1 cancel

**cancel的原理基于MySQL的主从复制。**

**MySQL的主从复制：当master的节点执行写操作时，会将该命令放入到binlog日志中，slave会在起一个IO Thread隔一段时间监听binlog文件是否发生改变，如果发生改变，master会为每一个IO Thread启动一个dump Thread将binlog的日志以二进制的方式发送到slave，slave接收到的二进制文件会保存到本地的relay文件中，之后slave会以启动一个SQL Thread执行本地的relay文件，进行数据同步**

**cancel就模仿了这个机制，让master以为cancel是一个从机，然后让master不断发送日志数据到cancel，cancel再记录到自己的日志中，从而我们可以获取到MySQL的写操作信息。**

## 12、雪崩、穿透和击穿

1、**雪崩原因：**

- **Redis服务器挂掉了**
- **大量的key失效**

**解决和预防：**

- **主从复制+哨兵**
- **集群**
- **开启AOF和RDB，重启时快速恢复数据**
- **key的过期时间随机**
- **用钱阿里云服务器**
- **多缓存结合，ehcache+redis**
- **服务降级**

------

2、**穿透原因：**

- **有个请求过来时发现redis和mysql都没有，就重复发起恶意请求**

**解决：**

- **可能是恶意请求**
  - **为不重复key、缺省值或者空值时，当Redis和MySQL都查不到，会在Redis做一次备份，下次过来时，Redis就会返回一个空值回去 **
  - **为重复key时，这个时候可能会造成redis的内存短暂飙升。因为无关紧要的key会越来越多**
- **布隆过滤器：对存在的key设置白名单，存在才让过去，不存在直接返回。谷歌有个Guava过滤器。会有那么百分之一会漏掉，不过无关紧要**

------

3、**击穿原因：**

- **key的时间刚好过期，这个时候大量的请求过来**

**解决：**

- **对重要的key设置为永不过期**
- **双重redis缓存，A缓存负责接受数据，B缓存作为保底。**
- **对这个数据加个互斥锁，第一个进来的时候，其他请求先等待，然后数据更新到Redis即可**

## 13、过期淘汰

**内存设置注意事项：**

- **默认内存大小：0，代表不限制Redis内存使用。**
- **一般Redis大小设置内存的四分之三。**
- **如果超出了Redis设置的内存大小，会造成内存溢出**

------

**注意：当key过期时是不会立马删除的，删除会采用具体的策略。**

**三种删除策略**

- **立即删除，缺点：对CPU不友好，用处理器性能换取空间。**
- **惰性删除，缺点：对内存不友好，用到了发现过期才删，用存储空间换取性能。**
- **定期删除，定期抽样key，判断是否过期。**

------

**Redis缓存淘汰策略**

![](https://s3.bmp.ovh/imgs/2023/06/01/1d0fd39bc566b19d.png)

**LRU / LFU的区别：2 1 2 1 2 3 4，LRU：最后一次发生调度的时间长短。LFU：看一定时间段内页面被使用的频率!**

- **LRU：（Least Recently Used）最近一段时间未被使用的。**

以下例子，3内存块：因为前面2和1有 重复，所以不算，当到4页面时，发现内存块不足，发生缺页中断，看前面最近谁没有被使用过，就是1，把1干掉4上位。

2	2	2	2	2	2

  	1	1	1	1	4

​						3	3

- **LFU：最不常用页面置换算法**

4发生缺页中断，往前看，发现3使用的次数最少，直接把3干掉，4上位。

2	2	2	2	2	2

  	1	1	1	1	1

​						3	4

![](https://s3.bmp.ovh/imgs/2023/06/01/b248b1209a15e40e.png)

## 14、五大数据类型的底层实现

![](https://s3.bmp.ovh/imgs/2023/06/01/9360bbd01b56c6a1.png)

